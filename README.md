# üìù Sentiment Analysis: BERT (RoBERTa-base) vs Naive Bayes

–í —ç—Ç–æ–º –ø—Ä–æ–µ–∫—Ç–µ —è –ø—Ä–æ–≤—ë–ª —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–≤—É—Ö –ø–æ–¥—Ö–æ–¥–æ–≤ –∫ –∞–Ω–∞–ª–∏–∑—É —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞:

- üîπ **–ù–∞–∏–≤–Ω—ã–π –ë–∞–π–µ—Å** ‚Äî –ø—Ä–æ—Å—Ç–∞—è –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∞—è –º–æ–¥–µ–ª—å –¥–ª—è NLP.  
- üîπ **–î–æ–æ–±—É—á–µ–Ω–Ω—ã–π BERT (RoBERTa-base)** ‚Äî —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–Ω–∞—è –º–æ–¥–µ–ª—å, –¥–æ–æ–±—É—á–µ–Ω–Ω–∞—è –Ω–∞ –∫–∞—Å—Ç–æ–º–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ.  

---

## üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã

- **–ù–∞–∏–≤–Ω—ã–π –ë–∞–π–µ—Å** —Å–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è —Å –∫–æ—Ä–æ—Ç–∫–∏–º–∏ —Ç–µ–∫—Å—Ç–∞–º–∏, –Ω–æ —Ö—É–∂–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ –¥–ª–∏–Ω–Ω—ã—Ö –∏ —Å–ª–æ–∂–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–∞—Ö.  
- **RoBERTa-base (fine-tuned)** –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –±–æ–ª–µ–µ –≤—ã—Å–æ–∫—É—é —Ç–æ—á–Ω–æ—Å—Ç—å –∏ —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –∫ –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω—ã–º —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞–º.  

–§–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –¥–æ—Å—Ç—É–ø–Ω–∞ –Ω–∞ **Hugging Face Hub**:  
üëâ [levshaone/model_sentiment](https://huggingface.co/levshaone/model_sentiment)

---

## üöÄ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏

### üîπ –ü—Ä—è–º–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
```python
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch

# –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏–∑ Hugging Face Hub
model_name = "levshaone/sentiment_model"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)
model.eval()

id2label = {0: "negative", 1: "positive"}

def predict(text: str):
    encoding = tokenizer(text, return_tensors="pt", truncation=True, padding=True)
    with torch.no_grad():
        outputs = model(**encoding)
        preds = torch.argmax(outputs.logits, dim=-1).item()
    return id2label[preds]

print(predict("I really love this movie!"))   # positive
print(predict("This film was terrible..."))   # negative

### üîπ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ Telegram-–±–æ—Ç–∞
–ü–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è –∏ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ –Ω–∞ Hugging Face –µ—ë –º–æ–∂–Ω–æ —Å—Ä–∞–∑—É –ø—Ä–∏–º–µ–Ω—è—Ç—å –≤ —Ä–µ–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–∞—Ö.  
–û–¥–∏–Ω –∏–∑ —É–¥–æ–±–Ω—ã—Ö —Å–ø–æ—Å–æ–±–æ–≤ ‚Äî –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ **Telegram-–±–æ—Ç–∞**, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –≤ —Ä–µ–∂–∏–º–µ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏.

(—Ç—É—Ç —Ç–≤–æ–π –∫–æ–¥ –±–æ—Ç–∞)

---

## üì± –ü—Ä–∏–º–µ—Ä—ã —Ä–∞–±–æ—Ç—ã Telegram-–±–æ—Ç–∞

–ù–∏–∂–µ –ø–æ–∫–∞–∑–∞–Ω—ã –ø—Ä–∏–º–µ—Ä—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –º–æ–¥–µ–ª–∏ –ø—Ä—è–º–æ –≤ —á–∞—Ç–µ:

### üîπ –ü–æ–∑–∏—Ç–∏–≤–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
![positive example](https://github.com/icelevsha/BERT_vs_Naive_Bayes/blob/main/images/negative.png)


### üîπ –ù–µ–≥–∞—Ç–∏–≤–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
![negative example](images/negative_example.png)
